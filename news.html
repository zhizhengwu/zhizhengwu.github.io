
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>News & Updates | Zhizheng Wu</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
      tailwind.config = {
        theme: {
          extend: {
            colors: {
              academic: {
                50: '#f8fafc',
                900: '#0f172a',
              },
              primary: {
                DEFAULT: '#2563eb',
              }
            },
            fontFamily: {
              sans: ['Inter', 'system-ui', 'sans-serif'],
              serif: ['Merriweather', 'Georgia', 'serif'],
            }
          }
        }
      }
    </script>
    <style>
      @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Merriweather:ital,wght@0,300;0,400;0,700;1,400&display=swap');
      body { font-family: 'Inter', sans-serif; }
      h1, h2 { font-family: 'Merriweather', serif; }
      a { color: #2563eb; text-decoration: underline; }
      a:hover { color: #1d4ed8; }
    </style>
</head>
<body class="bg-academic-50 text-slate-900 antialiased">
    <div class="max-w-4xl mx-auto px-6 py-12">
        <div class="mb-12">
            <a href="index.html" class="text-primary hover:underline mb-4 inline-block no-underline">&larr; Back to Home</a>
            <h1 class="text-4xl md:text-5xl font-bold text-academic-900 mb-4">News & Updates</h1>
            <p class="text-lg text-slate-600">Archive of research news, awards, grants, and talks.</p>
        </div>

        <div class="space-y-4">
            
            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-11-08</div>
                 <div class="text-slate-800 leading-relaxed">
                    Yuancheng Wang received the Best Poster Award at <a href="https://speechteam.feishu.cn/record/VRMarmQSceAz5lcm2SNc2cC0nEc">2025年声纹处理研究与应用学术研讨会</a>.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-11-08</div>
                 <div class="text-slate-800 leading-relaxed">
                    <a href="https://arxiv.org/abs/2508.17229">GenSR-Pref</a> is accepted to AAAI 2026. Congrats to Junan Zhang.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-11-06</div>
                 <div class="text-slate-800 leading-relaxed">
                    Prof. Zhizheng Wu gave an invited talk on “Research progress in Speech Tokenize/Codec” at 华为2025媒体技术峰会.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-11-01</div>
                 <div class="text-slate-800 leading-relaxed">
                    Prof. Zhizheng Wu gave an invited talk on “语音处理技术研究与应用进展” at RTE大会.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-10-25</div>
                 <div class="text-slate-800 leading-relaxed">
                    <a href="https://arxiv.org/abs/2508.16790">TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling</a> gets the honourable Mention Awards at Nanyang Speech Technology Forum (NYSF) 2025. <a href="https://arxiv.org/abs/2411.19770">Noro: Noise-Robust One-shot Voice Conversion with Hidden Speaker Representation Learning</a> gets the Best Paper Finalist at APSIPA 2025. Congrats to Haorui He, Yuancheng Wang, Xueyao Zhang, Li Wang and team.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-10-25</div>
                 <div class="text-slate-800 leading-relaxed">
                    Prof. Zhizheng Wu gave an invited talk at 杭州电子科技大学计算机学科高质量发展论坛.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-10-17</div>
                 <div class="text-slate-800 leading-relaxed">
                    <a href="https://speechteam.feishu.cn/record/IX9or8Xfxe9OkpcraoAcdPc8nZd">Junan Zhang</a> received the Best Presentation Award at <a href="https://www.ncmmsc.org.cn/xslt/">NCMMSC 2025</a>.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-09-19</div>
                 <div class="text-slate-800 leading-relaxed">
                    <a href="https://doi.org/10.48550/arXiv.2502.03128">Papers</a> <a href="https://doi.org/10.48550/arXiv.2508.16790">from</a> our team are accepted by NeurIPS 2025. Congrats to Yuancheng Wang, Jiachen Zheng, Junan Zhang, Xueyao Zhang, Huan Liao and team.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-09-14</div>
                 <div class="text-slate-800 leading-relaxed">
                    <a href="https://doi.org/10.48550/arXiv.2501.15907">Paper</a> from our team is accepted by IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2025. Congrats to Haorui He, Chaoren Wang and team.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-09-10</div>
                 <div class="text-slate-800 leading-relaxed">
                    <a href="https://speechteam.feishu.cn/record/P3b8rvck5eZR1Xcu8mgcFwGxnKe">Prof. Zhizheng Wu and Junan Zhang, Huan Liao, Yudong Li joined SLAI.</a>
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-08-29</div>
                 <div class="text-slate-800 leading-relaxed">
                    Prof. Zhizheng Wu gave an invited talk on “基于语义的生成式语音增强” at 2025先进音频技术竞赛暨华为终端音频技术论坛.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-08-29</div>
                 <div class="text-slate-800 leading-relaxed">
                    Junan Zhang is invited to lead the <a href="https://ccf-aatc.org.cn/">CCF AATC Track 1: Speech Restoration Challenge</a>, drawing 100+ teams to tackle real-world audio challenges.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-08-07</div>
                 <div class="text-slate-800 leading-relaxed">
                    Prof. Zhizheng Wu gave an invited talk on “语音模型与人类偏好对齐研究” at 华为ICT AI算法论坛.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-08-06</div>
                 <div class="text-slate-800 leading-relaxed">
                    <a href="https://speechteam.feishu.cn/record/S0A0rv2bWe8wGjcRqRScj1Y9n7e">Prof. Zhizheng Wu gave an invited talk on “Reinforcement Learning for text-to-speech synthesis” at International Asian Language processing conference (IALP2025).</a>
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-08-01</div>
                 <div class="text-slate-800 leading-relaxed">
                    Congrats to Jiaqi Li and Xueyao Zhang, who start an internship at tiktok.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-06-26</div>
                 <div class="text-slate-800 leading-relaxed">
                    Yuancheng Wang is invited to give a <a href="https://mp.weixin.qq.com/s/5oxKwoYx4XpQAkg1j7ow0Q">talk</a> at the Xmart 学生论坛.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-06-22</div>
                 <div class="text-slate-800 leading-relaxed">
                    <a href="https://arxiv.org/abs/2501.15417">Paper</a> from our team is accepted by TASLP 2025. Congrats to Junan Zhang and team.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-06-14</div>
                 <div class="text-slate-800 leading-relaxed">
                    <a href="https://speechteam.feishu.cn/record/WFBprWBjSe6BlbclZmucOgE6n5e">Junan Zhang is invited to give a <a href="https://giac.msup.com.cn/2025sz/course?id=18426">talk</a> at the 12th GIAC全球互联网架构大会.</a>
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-06-11</div>
                 <div class="text-slate-800 leading-relaxed">
                    Junan Zhang is invited to give a <a href="https://mp.weixin.qq.com/s/UoCSXKsgd0KLNExdyHgT2A">talk</a> online at speechhome(语音之家).
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-05-28</div>
                 <div class="text-slate-800 leading-relaxed">
                    <a href="https://arxiv.org/abs/2505.15368">Paper</a> from our team is accepted by Interspeech 2025. Congrats to <a href="https://speechteam.feishu.cn/record/SZigrMGJgef7iocNi1GcJIRWnph">Yicheng Gu</a> and team.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-05-28</div>
                 <div class="text-slate-800 leading-relaxed">
                    <a href="https://arxiv.org/abs/2504.04589">Paper</a> about Virtual Analog Modeling got accepted by DAFx 2025. Congrats to Yicheng Gu and team.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-05-27</div>
                 <div class="text-slate-800 leading-relaxed">
                    Two members of our team Yuancheng Wang(2nd year PhD student CUHK-Shenzhen) and Junyi Ao performed research at Meta (California, USA) as an intern during summer 2025.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-05-17</div>
                 <div class="text-slate-800 leading-relaxed">
                    <a href="https://speechteam.feishu.cn/record/Xi56rh4kDeyWMvchIb5ciyx0nLh">Paper</a> <a href="https://arxiv.org/abs/2505.04113">from</a> our team is accepted by ACL 2025. Congrats to Xueyao Zhang and Yuancheng Wang.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-04</div>
                 <div class="text-slate-800 leading-relaxed">
                    Congrats to Jiaqi Li (1st year PhD student CUHK-Shenzhen) and Chaoren Wang (UG CUHK-Shenzhen), who start an internship at Microsoft Research.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-04-28</div>
                 <div class="text-slate-800 leading-relaxed">
                    Xueyao Zhang, Yuancheng Wang, and Junan Zhang are invited to give talks at the National University of Singapore (NUS).
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-04-07</div>
                 <div class="text-slate-800 leading-relaxed">
                    Xueyao Zhang organizing an academic competition, <a href="https://www.vc-challenge.org/">Singing Voice Conversion Challenge 2025</a>.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-02-06</div>
                 <div class="text-slate-800 leading-relaxed">
                    Yuancheng Wang is invited to give a <a href="https://b23.tv/15iJawA">talk</a> at the speechhome(语音之家).
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2025-01-25</div>
                 <div class="text-slate-800 leading-relaxed">
                    <a href="https://speechteam.feishu.cn/record/SQNlrNaaFeAQcicZ3TYcNifynge">Three papers from our team are accepted by ICLR 2025. Congrats to <a href="https://openreview.net/forum?id=anQDiQZhDP">Xueyao Zhang,</a> <a href="https://arxiv.org/abs/2409.00750">Yuancheng Wang</a> and <a href="https://openreview.net/forum?id=z8sxoCYgmd">Junan Zhang</a>.</a>
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-11-18</div>
                 <div class="text-slate-800 leading-relaxed">
                    Amphion now has 7.6k stars! Congrats to team!
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-11-09</div>
                 <div class="text-slate-800 leading-relaxed">
                    Prof. Zhizheng Wu gave an invited talk on data processing for large-scale speech model.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-11-07</div>
                 <div class="text-slate-800 leading-relaxed">
                    Prof. Zhizheng Wu gave a tutorial on <a href="http://www.iscslp2024.com/homeTutorials">“Advances in the development of large-scale speech generation model”</a> at ISCSLP 2024.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-10-28</div>
                 <div class="text-slate-800 leading-relaxed">
                    We released <a href="https://github.com/open-mmlab/Amphion/blob/main/models/tts/maskgct">code</a> (2.5k+ stars in one week) and <a href="https://huggingface.co/amphion/maskgct">checkpoints</a> of <a href="https://arxiv.org/abs/2409.00750">MaskGCT</a>, which has been used in <a href="https://voice.funnycp.com/#/">Quwan All Voice</a>, Congrats to team.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-10-26</div>
                 <div class="text-slate-800 leading-relaxed">
                    Prof. Zhizheng Wu was invited to give a presentation on "Large Speech Models with Emotional Intelligence" at the 2024 RTE Conference.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-10-24</div>
                 <div class="text-slate-800 leading-relaxed">
                    <a href="https://dl.acm.org/doi/abs/10.1145/3705304">Paper</a> from our team is accepted by TOSEM 2025, Congrats to Junan Zhang.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-10-20</div>
                 <div class="text-slate-800 leading-relaxed">
                    Congrats to Li Wang, who received the <a href="https://drwuz.com/images/liwang_award_2024.jpeg">best presentation award</a> from the Speaker Processing workshop in Beijing.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-09-02</div>
                 <div class="text-slate-800 leading-relaxed">
                    Prof. Zhizheng Wu gave an invited survey talk on ‘Zero-Shot Text-to-Speech Synthesis’ at Interspeech 2024.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-08-25</div>
                 <div class="text-slate-800 leading-relaxed">
                    Five papers from our team are accepted by IEEE Spoken Language Technology Workshop 2024. Congrats to Xueyao Zhang, Li Wang, Yuancheng Wang, Jiaqi Li, Junan Zhang, Zihao Fang, Yicheng Gu, Chaoren Wang and team.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-07-10</div>
                 <div class="text-slate-800 leading-relaxed">
                    十万小时的<a href="https://arxiv.org/abs/2407.05361">Emilia</a>数据集已开源
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-05-04</div>
                 <div class="text-slate-800 leading-relaxed">
                    Prof. Zhizheng Wu has been invited to serve as an Associate Editor for <i>IEEE Signal Processing Letters</i>.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-05-02</div>
                 <div class="text-slate-800 leading-relaxed">
                    <a href="https://arxiv.org/abs/2403.03100">NaturalSpeech 3</a>被ICML接收。NS3中的FACodec已在<a href="https://github.com/open-mmlab/Amphion">Amphion</a>中开源。
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-04-15</div>
                 <div class="text-slate-800 leading-relaxed">
                    Amphion受邀在IEEE ICASSP 2024上展示.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-04-14</div>
                 <div class="text-slate-800 leading-relaxed">
                    Jiaqi Li has been awarded the IEEE Travel Grant.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-04-08</div>
                 <div class="text-slate-800 leading-relaxed">
                    港中大（深圳）-趣丸科技联合实验中心（主任：武执政博士）正式签署执行，期待开花结果。
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-03-28</div>
                 <div class="text-slate-800 leading-relaxed">
                    Prof. Zhizheng Wu was invited to present the Amphion open-source project at the 2024 China International Audio Industry Conference.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-03-24</div>
                 <div class="text-slate-800 leading-relaxed">
                    联合深圳市人工智能学会，成功举办ICASSP 2024论文预讲会。
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-03-20</div>
                 <div class="text-slate-800 leading-relaxed">
                    Prof. Zhizheng Wu受邀在深圳彩田学校面向5-7年级学生科普生成式人工智能，第一次面向中小学生讲人工智能。
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-03-06</div>
                 <div class="text-slate-800 leading-relaxed">
                    Xueyao Zhang(2nd year PhD student CUHK-Shenzhen)performed research at Meta (California, USA) as an intern during summer 2024.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2024-01-01</div>
                 <div class="text-slate-800 leading-relaxed">
                    深圳市跨模态认知重点实验室获批（主任：李海洲教授，副主任：于天维教授、武执政博士）。
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2023-12-18</div>
                 <div class="text-slate-800 leading-relaxed">
                    <a href="https://github.com/open-mmlab/Amphion">Amphion v0.1</a> is released. It is rated as an A+++ project by <a href="https://www.bilibili.com/video/BV18w411V7iq">top Silcon Valley investor</a>.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2023-12-09</div>
                 <div class="text-slate-800 leading-relaxed">
                    Three papers from our team are accepted by ICASSP 2024. Congrats to Yicheng, Jiaqi and Li.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2023-10-26</div>
                 <div class="text-slate-800 leading-relaxed">
                    Congrats to Xueyao Zhang (2nd year PhD student CUHK-Shenzhen) and team, whose <a href="https://arxiv.org/abs/2310.11160">paper on Singing Voice Conversion</a> accepted by NeurIPS 2023 Workshop on Machine Learning for Audio.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2023-10-20</div>
                 <div class="text-slate-800 leading-relaxed">
                    Prof. Zhizheng Wu <a href="https://mp.weixin.qq.com/s/eEOGWlp_vLEyZXi-M5plGQ">gave an invited talk on voice anti-spoofing at the Symposium on Speaker Verification and its Application</a>.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2023-10-19</div>
                 <div class="text-slate-800 leading-relaxed">
                    Prof. Zhizheng Wu <a href="https://news.nankai.edu.cn/dcxy/system/2023/10/21/030058409.shtml">visited Nankai University, and was appointed as an external advisor</a>.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2023-10-13</div>
                 <div class="text-slate-800 leading-relaxed">
                    Prof. Zhizheng Wu was listed in the Stanford ‘World’s Top 2% Scientists’ list. See the <a href="https://drwuz.com/news/files/shenzhen_tv_interview.mp4">interview by Shenzhen TV</a>.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2023-10-10</div>
                 <div class="text-slate-800 leading-relaxed">
                    Congrats to Jiaqi Li (UG CUHK-Shenzhen), who starts an internship at Microsoft Research.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2023-09-22</div>
                 <div class="text-slate-800 leading-relaxed">
                    Congrats to Yuancheng Wang (1st year PhD student CUHK-Shenzhen, UG at CUHK-Shenzhen) and team, whose <a href="https://arxiv.org/abs/2304.00830">paper on Audio Editing</a> accepted by NeurIPS 2023.
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2023-08-27</div>
                 <div class="text-slate-800 leading-relaxed">
                    The proposal to host IEEE SLT workshop 2024 led by Prof. Wu was approved. See you in Macao from Dec 9th to 12th, 2024!
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2023-08-19</div>
                 <div class="text-slate-800 leading-relaxed">
                    Prof. Zhizheng Wu gave a keynote speech at the IJCAI 2023 Workshop on Deepfake Audio Detection and Analysis (DADA 2023) on <a href="http://addchallenge.cn/dada2023">Recent Advances in Voice Spoofing Detection</a>
                 </div>
            </div>

            <div class="bg-white p-6 rounded-xl border border-slate-200 shadow-sm">
                 <div class="text-sm font-bold text-slate-500 mb-2">2023-04</div>
                 <div class="text-slate-800 leading-relaxed">
                    Xueyao Zhang (1st year PhD student CUHK-Shenzhen) was admitted by Tencent Rhino-Bird Talent Program 腾讯犀牛鸟精英人才计划 (Top 50+ of China).
                 </div>
            </div>

        </div>
        
        <div class="mt-12 text-center">
            <a href="index.html" class="inline-block px-6 py-3 bg-academic-900 text-white rounded-lg hover:bg-slate-800 transition-colors no-underline">Back to Home</a>
        </div>
    </div>
</body>
</html>
